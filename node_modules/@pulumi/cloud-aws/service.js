"use strict";
// Copyright 2016-2018, Pulumi Corporation.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", { value: true });
const aws = require("@pulumi/aws");
const pulumi = require("@pulumi/pulumi");
const pulumi_1 = require("@pulumi/pulumi");
const docker = require("@pulumi/docker");
const config = require("./config");
const shared_1 = require("./shared");
const utils = require("./utils");
// createLoadBalancer allocates a new Load Balancer and TargetGroup that can be attached to a Service container and port
// pair.
function createLoadBalancer(parent, cluster, serviceName, containerName, portMapping, network) {
    // Load balancers need *very* short names, so we unfortunately have to hash here.
    //
    // Note: Technically, we can only support one LB per service, so only the service name is needed here, but we
    // anticipate this will not always be the case, so we include a set of values which must be unique.
    const longName = `${serviceName}-${containerName}-${portMapping.port}`;
    const shortName = utils.sha1hash(`${longName}`);
    // Create an internal load balancer if requested.
    const internal = network.usePrivateSubnets && !portMapping.external;
    const portMappingProtocol = portMapping.protocol || "tcp";
    // See what kind of load balancer to create (application L7 for HTTP(S) traffic, or network L4 otherwise).
    // Also ensure that we have an SSL certificate for termination at the LB, if that was requested.
    let protocol;
    let targetProtocol;
    let useAppLoadBalancer;
    let useCertificateARN;
    switch (portMappingProtocol) {
        case "https":
            protocol = "HTTPS";
            // Set the target protocol to HTTP, so that the ELB terminates the SSL traffic.
            // IDEA: eventually we should let users choose where the SSL termination occurs.
            targetProtocol = "HTTP";
            useAppLoadBalancer = true;
            useCertificateARN = config.acmCertificateARN;
            if (!useCertificateARN) {
                throw new Error("Cannot create Service for HTTPS trafic. No ACM certificate ARN configured.");
            }
            break;
        case "http":
            protocol = "HTTP";
            targetProtocol = "HTTP";
            useAppLoadBalancer = true;
            break;
        case "udp":
            throw new Error("UDP protocol unsupported for Services");
        case "tcp":
            protocol = "TCP";
            targetProtocol = "TCP";
            useAppLoadBalancer = false;
            break;
        default:
            throw new Error(`Unrecognized Service protocol: ${portMapping.protocol}`);
    }
    const loadBalancer = new aws.elasticloadbalancingv2.LoadBalancer(shortName, {
        loadBalancerType: useAppLoadBalancer ? "application" : "network",
        subnets: network.publicSubnetIds,
        internal: internal,
        // If this is an application LB, we need to associate it with the ECS cluster's security group, so
        // that traffic on any ports can reach it.  Otherwise, leave blank, and default to the VPC's group.
        securityGroups: (useAppLoadBalancer && cluster.securityGroupId) ? [cluster.securityGroupId] : undefined,
        tags: {
            Name: longName,
        },
    }, { parent: parent });
    // Create the target group for the new container/port pair.
    const target = new aws.elasticloadbalancingv2.TargetGroup(shortName, {
        port: portMapping.targetPort || portMapping.port,
        protocol: targetProtocol,
        vpcId: network.vpcId,
        deregistrationDelay: 180,
        tags: {
            Name: longName,
        },
        targetType: "ip",
    }, { parent: parent });
    // Listen on the requested port on the LB and forward to the target.
    const listener = new aws.elasticloadbalancingv2.Listener(longName, {
        loadBalancerArn: loadBalancer.arn,
        protocol: protocol,
        certificateArn: useCertificateARN,
        port: portMapping.port,
        defaultActions: [{
                type: "forward",
                targetGroupArn: target.arn,
            }],
        // If SSL is used, we automatically insert the recommended ELB security policy from
        // http://docs.aws.amazon.com/elasticloadbalancing/latest/application/create-https-listener.html.
        sslPolicy: useCertificateARN ? "ELBSecurityPolicy-2016-08" : undefined,
    }, { parent: parent });
    return {
        loadBalancer: loadBalancer,
        targetGroup: target,
        protocol: portMappingProtocol,
    };
}
function getBuildImageName(build) {
    // Produce a hash of the build context and use that for the image name.
    let buildSig;
    if (typeof build === "string") {
        buildSig = build;
    }
    else {
        buildSig = build.context || ".";
        if (build.dockerfile) {
            buildSig += `;dockerfile=${build.dockerfile}`;
        }
        if (build.args) {
            for (const arg of Object.keys(build.args)) {
                buildSig += `;arg[${arg}]=${build.args[arg]}`;
            }
        }
    }
    return shared_1.createNameWithStackInfo(`${utils.sha1hash(buildSig)}-container`);
}
// repositories contains a cache of already created ECR repositories.
const repositories = new Map();
// getOrCreateRepository returns the ECR repository for this image, lazily allocating if necessary.
function getOrCreateRepository(imageName) {
    let repository = repositories.get(imageName);
    if (!repository) {
        repository = new aws.ecr.Repository(imageName.toLowerCase());
        repositories.set(imageName, repository);
        // Set a default lifecycle policy such that at most a single untagged image is retained.
        // We tag all cached build layers as well as the final image, so those images will never expire.
        const lifecyclePolicyDocument = {
            rules: [{
                    rulePriority: 10,
                    description: "remove untagged images",
                    selection: {
                        tagStatus: "untagged",
                        countType: "imageCountMoreThan",
                        countNumber: 1,
                    },
                    action: {
                        type: "expire",
                    },
                }],
        };
        const lifecyclePolicy = new aws.ecr.LifecyclePolicy(imageName.toLowerCase(), {
            policy: JSON.stringify(lifecyclePolicyDocument),
            repository: repository.name,
        });
    }
    return repository;
}
// buildImageCache remembers the digests for all past built images, keyed by image name.
const buildImageCache = new Map();
// makeServiceEnvName turns a service name into something suitable for an environment variable.
function makeServiceEnvName(service) {
    return service.toUpperCase().replace(/-/g, "_");
}
// computeImage turns the `image`, `function` or `build` setting on a `cloud.Container` into a valid Docker image
// name and environment which can be used in an ECS TaskDefinition.
function computeImage(parent, container, ports) {
    // Start with a copy from the container specification.
    const preEnv = Object.assign({}, container.environment || {});
    // Now add entries for service discovery amongst containers exposing endpoints.
    if (ports) {
        for (const service of Object.keys(ports)) {
            let firstPort = true;
            const serviceEnv = makeServiceEnvName(service);
            for (const port of Object.keys(ports[service])) {
                const info = ports[service][parseInt(port, 10)];
                const hostname = info.host.dnsName;
                const hostport = info.hostPort.toString();
                const hostproto = info.hostProtocol;
                // Populate Kubernetes and Docker links compatible environment variables.  These take the form:
                //
                //     Kubernetes:
                //         {SVCNAME}_SERVICE_HOST=10.0.0.11 (or DNS name)
                //         {SVCNAME}_SERVICE_PORT=6379
                //     Docker links:
                //         {SVCNAME}_PORT=tcp://10.0.0.11:6379 (or DNS address)
                //         {SVCNAME}_PORT_6379_TCP=tcp://10.0.0.11:6379 (or DNS address)
                //         {SVCNAME}_PORT_6379_TCP_PROTO=tcp
                //         {SVCNAME}_PORT_6379_TCP_PORT=6379
                //         {SVCNAME}_PORT_6379_TCP_ADDR=10.0.0.11 (or DNS name)
                //
                // See https://kubernetes.io/docs/concepts/services-networking/service/#discovering-services and
                // https://docs.docker.com/engine/userguide/networking/default_network/dockerlinks/ for more info.
                if (firstPort) {
                    preEnv[`${serviceEnv}_SERVICE_HOST`] = hostname;
                    preEnv[`${serviceEnv}_SERVICE_PORT`] = hostport;
                }
                firstPort = false;
                const fullHost = pulumi_1.interpolate `${hostproto}://${hostname}:${hostport}`;
                preEnv[`${serviceEnv}_PORT`] = fullHost;
                preEnv[`${serviceEnv}_PORT_${port}_TCP`] = fullHost;
                preEnv[`${serviceEnv}_PORT_${port}_TCP_PROTO`] = hostproto;
                preEnv[`${serviceEnv}_PORT_${port}_TCP_PORT`] = hostport;
                preEnv[`${serviceEnv}_PORT_${port}_TCP_ADDR`] = hostname;
            }
        }
    }
    if (container.build) {
        return computeImageFromBuild(parent, preEnv, container.build);
    }
    else if (container.image) {
        return createImageOptions(container.image, preEnv);
    }
    else if (container.function) {
        return computeImageFromFunction(container.function, preEnv);
    }
    else {
        throw new Error("Invalid container definition: `image`, `build`, or `function` must be provided");
    }
}
function computeImageFromBuild(parent, preEnv, build) {
    const imageName = getBuildImageName(build);
    const repository = getOrCreateRepository(imageName);
    // This is a container to build; produce a name, either user-specified or auto-computed.
    pulumi.log.debug(`Building container image at '${build}'`, repository);
    const { repositoryUrl, registryId } = repository;
    return pulumi.all([repositoryUrl, registryId]).apply(([repositoryUrl, registryId]) => computeImageFromBuildWorker(preEnv, build, imageName, repositoryUrl, registryId, parent));
}
function computeImageFromBuildWorker(preEnv, build, imageName, repositoryUrl, registryId, logResource) {
    // See if we've already built this.
    let uniqueImageName = buildImageCache.get(imageName);
    if (uniqueImageName) {
        uniqueImageName.apply(d => pulumi.log.debug(`    already built: ${imageName} (${d})`, logResource));
    }
    else {
        // If we haven't, build and push the local build context to the ECR repository.  Then return
        // the unique image name we pushed to.  The name will change if the image changes ensuring
        // the TaskDefinition get's replaced IFF the built image changes.
        uniqueImageName = docker.buildAndPushImage(imageName, build, repositoryUrl, logResource, () => __awaiter(this, void 0, void 0, function* () {
            // Construct Docker registry auth data by getting the short-lived authorizationToken from ECR, and
            // extracting the username/password pair after base64-decoding the token.
            //
            // See: http://docs.aws.amazon.com/cli/latest/reference/ecr/get-authorization-token.html
            if (!registryId) {
                throw new Error("Expected registry ID to be defined during push");
            }
            const credentials = yield aws.ecr.getCredentials({ registryId: registryId });
            const decodedCredentials = Buffer.from(credentials.authorizationToken, "base64").toString();
            const [username, password] = decodedCredentials.split(":");
            if (!password || !username) {
                throw new Error("Invalid credentials");
            }
            return {
                registry: credentials.proxyEndpoint,
                username: username,
                password: password,
            };
        }));
        buildImageCache.set(imageName, uniqueImageName);
        uniqueImageName.apply(d => pulumi.log.debug(`    build complete: ${imageName} (${d})`, logResource));
    }
    return createImageOptions(uniqueImageName, preEnv);
}
function computeImageFromFunction(func, preEnv) {
    // TODO[pulumi/pulumi-cloud#85]: Put this in a real Pulumi-owned Docker image.
    // TODO[pulumi/pulumi-cloud#86]: Pass the full local zipped folder through to the container (via S3?)
    preEnv.PULUMI_SRC = pulumi.runtime.serializeFunction(func).then(v => v.text);
    // TODO[pulumi/pulumi-cloud#85]: move this to a Pulumi Docker Hub account.
    return createImageOptions("lukehoban/nodejsrunner", preEnv);
}
function createImageOptions(image, environment) {
    return pulumi.output({ image, environment });
}
// computeContainerDefinitions builds a ContainerDefinition for a provided Containers and LogGroup.
function computeContainerDefinitions(parent, containers, ports, logGroup) {
    const containerDefinitions = [];
    for (const containerName of Object.keys(containers)) {
        const container = containers[containerName];
        const containerDefinition = computeContainerDefinition(parent, containerName, container, ports, logGroup);
        containerDefinitions.push(containerDefinition);
    }
    return pulumi.all(containerDefinitions);
}
function computeContainerDefinition(parent, containerName, container, ports, logGroup) {
    const imageOptions = computeImage(parent, container, ports);
    const portMappings = (container.ports || []).map(p => ({
        containerPort: p.targetPort || p.port,
        // From https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html:
        // > For task definitions that use the awsvpc network mode, you should only specify the containerPort.
        // > The hostPort can be left blank or it must be the same value as the containerPort.
        //
        // However, if left blank, it will be automatically populated by AWS, potentially leading to dirty
        // diffs even when no changes have been made. Since we are currently always using `awsvpc` mode, we
        // go ahead and populate it with the same value as `containerPort`.
        //
        // See https://github.com/terraform-providers/terraform-provider-aws/issues/3401.
        hostPort: p.targetPort || p.port,
    }));
    return pulumi.all([imageOptions, container, logGroup.id])
        .apply(([imageOptions, container, logGroupId]) => {
        const keyValuePairs = [];
        for (const key of Object.keys(imageOptions.environment)) {
            keyValuePairs.push({ name: key, value: imageOptions.environment[key] });
        }
        const containerDefinition = {
            name: containerName,
            image: imageOptions.image,
            command: container.command,
            cpu: container.cpu,
            memory: container.memory,
            memoryReservation: container.memoryReservation,
            portMappings: portMappings,
            environment: keyValuePairs,
            mountPoints: (container.volumes || []).map(v => ({
                containerPath: v.containerPath,
                sourceVolume: getVolumeName(v.sourceVolume),
            })),
            logConfiguration: {
                logDriver: "awslogs",
                options: {
                    "awslogs-group": logGroupId,
                    "awslogs-region": aws.config.requireRegion(),
                    "awslogs-stream-prefix": containerName,
                },
            },
            dockerLabels: container.dockerLabels,
        };
        return containerDefinition;
    });
}
// The ECS Task assume role policy for Task Roles
const taskRolePolicy = {
    "Version": "2012-10-17",
    "Statement": [
        {
            "Action": "sts:AssumeRole",
            "Principal": {
                "Service": "ecs-tasks.amazonaws.com",
            },
            "Effect": "Allow",
            "Sid": "",
        },
    ],
};
// Lazily initialize the role to use for ECS Tasks
let taskRole;
function getTaskRole() {
    if (!taskRole) {
        taskRole = new aws.iam.Role(shared_1.createNameWithStackInfo("task"), {
            assumeRolePolicy: JSON.stringify(taskRolePolicy),
        }, { parent: shared_1.getGlobalInfrastructureResource() });
        // TODO[pulumi/pulumi-cloud#145]: These permissions are used for both Lambda and ECS compute.
        // We need to audit these permissions and potentially provide ways for users to directly configure these.
        const policies = shared_1.getComputeIAMRolePolicies();
        for (let i = 0; i < policies.length; i++) {
            const policyArn = policies[i];
            const _ = new aws.iam.RolePolicyAttachment(shared_1.createNameWithStackInfo(`task-${utils.sha1hash(policyArn)}`), {
                role: taskRole,
                policyArn: policyArn,
            }, { parent: shared_1.getGlobalInfrastructureResource() });
        }
    }
    return taskRole;
}
// Lazily initialize the role to use for ECS Task Execution
let executionRole;
function getExecutionRole() {
    if (!executionRole) {
        executionRole = new aws.iam.Role(shared_1.createNameWithStackInfo("execution"), {
            assumeRolePolicy: JSON.stringify(taskRolePolicy),
        }, { parent: shared_1.getGlobalInfrastructureResource() });
        const _ = new aws.iam.RolePolicyAttachment(shared_1.createNameWithStackInfo("execution"), {
            role: executionRole,
            policyArn: "arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy",
        }, { parent: shared_1.getGlobalInfrastructureResource() });
    }
    return executionRole;
}
// createTaskDefinition builds an ECS TaskDefinition object from a collection of `cloud.Containers`.
function createTaskDefinition(parent, name, containers, ports) {
    // Create a single log group for all logging associated with the Service
    const logGroup = new aws.cloudwatch.LogGroup(name, {
        retentionInDays: 1,
    }, { parent: parent });
    // Find all referenced Volumes.
    const volumes = [];
    for (const containerName of Object.keys(containers)) {
        const container = containers[containerName];
        // Collect referenced Volumes.
        if (container.volumes) {
            for (const volumeMount of container.volumes) {
                const volume = volumeMount.sourceVolume;
                volumes.push({
                    hostPath: getHostPath(volume),
                    name: getVolumeName(volume),
                });
            }
        }
    }
    // Create the task definition for the group of containers associated with this Service.
    const containerDefinitions = computeContainerDefinitions(parent, containers, ports, logGroup);
    // Compute the memory and CPU requirements of the task for Fargate
    const taskMemoryAndCPU = containerDefinitions.apply(d => taskMemoryAndCPUForContainers(d));
    const taskDefinition = new aws.ecs.TaskDefinition(name, {
        family: name,
        containerDefinitions: containerDefinitions.apply(d => JSON.stringify(d)),
        volumes: volumes,
        taskRoleArn: getTaskRole().arn,
        requiresCompatibilities: config.useFargate ? ["FARGATE"] : undefined,
        memory: config.useFargate ? taskMemoryAndCPU.memory : undefined,
        cpu: config.useFargate ? taskMemoryAndCPU.cpu : undefined,
        networkMode: "awsvpc",
        executionRoleArn: getExecutionRole().arn,
    }, { parent: parent });
    return {
        taskDefinition: taskDefinition,
        logGroup: logGroup,
    };
}
// Compute the memory and CPU requirements of the task for Fargate. See
// https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html#task_size.
function taskMemoryAndCPUForContainers(defs) {
    // Sum the requested memory and CPU for each container in the task.
    let minTaskMemory = 0;
    let minTaskCPU = 0;
    for (const containerDef of defs) {
        if (containerDef.memoryReservation) {
            minTaskMemory += containerDef.memoryReservation;
        }
        else if (containerDef.memory) {
            minTaskMemory += containerDef.memory;
        }
        if (containerDef.cpu) {
            minTaskCPU += containerDef.cpu;
        }
    }
    // Compute the smallest allowed Fargate memory value compatible with the requested minimum memory.
    let taskMemory;
    if (minTaskMemory <= 512) {
        taskMemory = 512;
    }
    else {
        const taskMemGB = minTaskMemory / 1024;
        const taskMemWholeGB = Math.ceil(taskMemGB);
        taskMemory = taskMemWholeGB * 1024;
    }
    // Allowed CPU values are powers of 2 between 256 and 4096.  We just ensure it's a power of 2 that is at least
    // 256. We leave the error case for requiring more CPU than is supported to ECS.
    let taskCPU = Math.pow(2, Math.ceil(Math.log2(Math.max(minTaskCPU, 256))));
    // Make sure we select an allowed CPU value for the specified memory.
    if (taskMemory > 16384) {
        taskCPU = Math.max(taskCPU, 4096);
    }
    else if (taskMemory > 8192) {
        taskCPU = Math.max(taskCPU, 2048);
    }
    else if (taskMemory > 4096) {
        taskCPU = Math.max(taskCPU, 1024);
    }
    else if (taskMemory > 2048) {
        taskCPU = Math.max(taskCPU, 512);
    }
    // Return the computed task memory and CPU values
    return {
        memory: `${taskMemory}`,
        cpu: `${taskCPU}`,
    };
}
function placementConstraintsForHost(host) {
    if (host && host.os) {
        return [{
                type: "memberOf",
                expression: `attribute:ecs.os-type == ${host.os}`,
            }];
    }
    return undefined;
}
class Service extends pulumi.ComponentResource {
    constructor(name, args, opts) {
        const cluster = shared_1.getCluster();
        if (!cluster) {
            throw new Error("Cannot create 'Service'.  Missing cluster config 'cloud-aws:ecsClusterARN'" +
                " or 'cloud-aws:ecsAutoCluster' or 'cloud-aws:useFargate'");
        }
        let containers;
        if (args.image || args.build || args.function) {
            if (args.containers) {
                throw new Error("Exactly one of image, build, function, or containers must be used, not multiple");
            }
            containers = { "default": args };
        }
        else if (args.containers) {
            containers = args.containers;
        }
        else {
            throw new Error("Missing one of image, build, function, or containers, specifying this service's containers");
        }
        const replicas = args.replicas === undefined ? 1 : args.replicas;
        const ports = {};
        super("cloud:service:Service", name, {}, opts);
        this.containers = containers;
        this.replicas = replicas;
        this.name = name;
        this.cluster = cluster;
        // Get the network to create the Service within.
        const network = shared_1.getOrCreateNetwork();
        // Create load balancer listeners/targets for each exposed port.
        const loadBalancers = [];
        let firstContainerName;
        let firstContainerPort;
        for (const containerName of Object.keys(containers)) {
            const container = containers[containerName];
            if (firstContainerName === undefined) {
                firstContainerName = containerName;
                if (container.ports && container.ports.length > 0) {
                    firstContainerPort = container.ports[0].port;
                }
            }
            ports[containerName] = {};
            if (container.ports) {
                for (const portMapping of container.ports) {
                    if (loadBalancers.length > 0) {
                        throw new Error("Only one port can currently be exposed per Service.");
                    }
                    const info = createLoadBalancer(this, cluster, name, containerName, portMapping, network);
                    ports[containerName][portMapping.port] = {
                        host: info.loadBalancer,
                        hostPort: portMapping.port,
                        hostProtocol: info.protocol,
                    };
                    loadBalancers.push({
                        containerName: containerName,
                        containerPort: portMapping.targetPort || portMapping.port,
                        targetGroupArn: info.targetGroup.arn,
                    });
                }
            }
        }
        // Create the task definition, parented to this component.
        const { taskDefinition, logGroup } = createTaskDefinition(this, name, containers, ports);
        // If the cluster has an autoscaling group, ensure the service depends on it being created.
        const serviceDependsOn = [];
        if (cluster.autoScalingGroupStack) {
            serviceDependsOn.push(cluster.autoScalingGroupStack);
        }
        // Create the service.
        const securityGroups = cluster.securityGroupId ? [cluster.securityGroupId] : [];
        this.ecsService = new aws.ecs.Service(name, {
            desiredCount: replicas,
            taskDefinition: taskDefinition.arn,
            cluster: cluster.ecsClusterARN,
            loadBalancers: loadBalancers,
            placementConstraints: placementConstraintsForHost(args.host),
            waitForSteadyState: args.waitForSteadyState === undefined ? true : args.waitForSteadyState,
            healthCheckGracePeriodSeconds: args.healthCheckGracePeriodSeconds,
            launchType: config.useFargate ? "FARGATE" : "EC2",
            networkConfiguration: {
                assignPublicIp: config.useFargate && !network.usePrivateSubnets,
                securityGroups: securityGroups,
                subnets: network.subnetIds,
            },
        }, { parent: this, dependsOn: serviceDependsOn });
        const localEndpoints = getEndpoints(ports);
        this.endpoints = localEndpoints;
        this.defaultEndpoint = firstContainerName === undefined || firstContainerPort === undefined
            ? pulumi.output(undefined)
            : this.endpoints.apply(ep => getEndpointHelper(ep, /*containerName:*/ undefined, /*containerPort:*/ undefined));
        this.getEndpoint = (containerName, containerPort) => __awaiter(this, void 0, void 0, function* () {
            const endpoints = localEndpoints.get();
            return getEndpointHelper(endpoints, containerName, containerPort);
        });
        this.taskDefinition = taskDefinition;
        this.logGroup = logGroup;
        this.registerOutputs();
    }
    // Expose the task role we create to clients (who will cast through <any>)
    // so they can attach their own policies.
    // TODO[pulumi/pulumi-cloud#145]: Find a better way to expose this functionality.
    static getTaskRole() {
        return getTaskRole();
    }
}
exports.Service = Service;
function getEndpointHelper(endpoints, containerName, containerPort) {
    containerName = containerName || Object.keys(endpoints)[0];
    if (!containerName) {
        throw new Error(`No containers available in this service`);
    }
    const containerPorts = endpoints[containerName] || {};
    containerPort = containerPort || +Object.keys(containerPorts)[0];
    if (!containerPort) {
        throw new Error(`No ports available in service container ${containerName}`);
    }
    const endpoint = containerPorts[containerPort];
    if (!endpoint) {
        throw new Error(`No exposed port for ${containerName} port ${containerPort}`);
    }
    return endpoint;
}
function getEndpoints(ports) {
    return pulumi.all(utils.apply(ports, portToExposedPort => {
        const inner = pulumi.all(utils.apply(portToExposedPort, exposedPort => exposedPort.host.dnsName.apply(d => ({
            port: exposedPort.hostPort, loadBalancer: exposedPort.host, hostname: d,
        }))));
        return inner;
    }));
}
const volumeNames = new Set();
// _Note_: In the current EFS-backed model, a Volume is purely virtual - it
// doesn't actually manage any underlying resource.  It is used just to provide
// a handle to a folder on the EFS share which can be mounted by container(s).
// On platforms like ACI, we may be able to actually provision a unique File
// Share per Volume to keep these independently manageable.  For now, on AWS
// though, we rely on this File Share having been set up as part of the ECS
// Cluster outside of @pulumi/cloud, and assume that that data has a lifetime
// longer than any individual deployment.
class SharedVolume extends pulumi.ComponentResource {
    constructor(name, opts) {
        if (volumeNames.has(name)) {
            throw new Error("Must provide a unique volume name");
        }
        super("cloud:volume:Volume", name, {}, opts);
        this.kind = "SharedVolume";
        this.name = name;
        volumeNames.add(name);
        this.registerOutputs({ kind: this.kind, name: this.name });
    }
}
exports.SharedVolume = SharedVolume;
class HostPathVolume {
    constructor(path) {
        this.kind = "HostPathVolume";
        this.path = path;
    }
}
exports.HostPathVolume = HostPathVolume;
function getVolumeName(volume) {
    const kind = volume.kind;
    switch (volume.kind) {
        case "HostPathVolume":
            return utils.sha1hash(`${volume.kind}:${volume.path}`);
        case "SharedVolume":
            // Ensure this is unique to avoid conflicts both in EFS and in the
            // TaskDefinition we pass to ECS.
            return utils.sha1hash(`${pulumi.getProject()}:${pulumi.getStack()}:${volume.kind}:${volume.name}`);
        default:
            throw new Error(`Volume was not a 'HostPathVolume' or 'SharedVolume': ${kind}`);
    }
}
function getHostPath(volume) {
    const kind = volume.kind;
    switch (volume.kind) {
        case "HostPathVolume":
            return volume.path;
        case "SharedVolume":
            const cluster = shared_1.getCluster();
            if (!cluster || !cluster.efsMountPath) {
                throw new Error("Cannot use 'Volume'.  Configured cluster does not support EFS.");
            }
            // Include the unique `getVolumeName` in the EFS host path to ensure this doesn't
            // clash with other deployments.
            return `${cluster.efsMountPath}/${volume.name}_${getVolumeName(volume)}`;
        default:
            throw new Error(`Volume was not a 'HostPathVolume' or 'SharedVolume': ${kind}`);
    }
}
/**
 * A Task represents a container which can be [run] dynamically whenever (and as many times as) needed.
 */
class Task extends pulumi.ComponentResource {
    constructor(name, container, opts) {
        super("cloud:task:Task", name, {}, opts);
        const network = shared_1.getOrCreateNetwork();
        const cluster = shared_1.getCluster();
        if (!cluster) {
            throw new Error("Cannot create 'Task'.  Missing cluster config 'cloud-aws:ecsClusterARN'" +
                " or 'cloud-aws:ecsAutoCluster' or 'cloud-aws:useFargate'");
        }
        this.cluster = cluster;
        const { taskDefinition, logGroup } = createTaskDefinition(this, name, { container: container });
        this.taskDefinition = taskDefinition;
        this.logGroup = logGroup;
        const clusterARN = this.cluster.ecsClusterARN;
        const taskDefinitionArn = this.taskDefinition.arn;
        const containerEnv = pulumi.all(container.environment || {});
        const subnetIds = pulumi.all(network.subnetIds);
        const securityGroups = cluster.securityGroupId;
        const useFargate = config.useFargate;
        const assignPublicIp = useFargate && !network.usePrivateSubnets;
        // tslint:disable-next-line:no-empty
        this.run = function (options) {
            return __awaiter(this, void 0, void 0, function* () {
                const awssdk = yield Promise.resolve().then(() => require("aws-sdk"));
                const ecs = new awssdk.ECS();
                // Extract the envrionment values from the options
                const env = [];
                yield addEnvironmentVariables(containerEnv.get());
                yield addEnvironmentVariables(options && options.environment);
                // Run the task
                const res = yield ecs.runTask({
                    cluster: clusterARN.get(),
                    taskDefinition: taskDefinitionArn.get(),
                    placementConstraints: placementConstraintsForHost(options && options.host),
                    launchType: useFargate ? "FARGATE" : "EC2",
                    networkConfiguration: {
                        awsvpcConfiguration: {
                            assignPublicIp: assignPublicIp ? "ENABLED" : "DISABLED",
                            securityGroups: [securityGroups.get()],
                            subnets: subnetIds.get(),
                        },
                    },
                    overrides: {
                        containerOverrides: [
                            {
                                name: "container",
                                environment: env,
                            },
                        ],
                    },
                }).promise();
                if (res.failures && res.failures.length > 0) {
                    throw new Error("Failed to start task:" + JSON.stringify(res.failures, null, ""));
                }
                return;
                // Local functions
                function addEnvironmentVariables(e) {
                    return __awaiter(this, void 0, void 0, function* () {
                        if (e) {
                            for (const key of Object.keys(e)) {
                                const envVal = e[key];
                                if (envVal) {
                                    env.push({ name: key, value: envVal });
                                }
                            }
                        }
                    });
                }
            });
        };
        this.registerOutputs({ cluster, taskDefinition: this.taskDefinition });
    }
    // See comment for Service.getTaskRole.
    static getTaskRole() {
        return getTaskRole();
    }
}
exports.Task = Task;
//# sourceMappingURL=service.js.map